{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5882e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import glob\n",
    "from prettytable import PrettyTable\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Linear,Sequential\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as func\n",
    "import time\n",
    "from math import isnan,isinf,log,exp\n",
    "import random\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c8b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname=r'../myp/tensors.p'\n",
    "rname='CIFAR10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82285964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../myp/tensors.p 15625\n"
     ]
    }
   ],
   "source": [
    "runs=[]\n",
    "f = open(fname,'rb')\n",
    "while(1):\n",
    "    try:\n",
    "        runs.append(pickle.load(f))\n",
    "    except EOFError:\n",
    "        break\n",
    "f.close()\n",
    "print(fname, len(runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78c07562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91e27560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(runs[0]['logmeasures']['synflow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10db5ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs[0]['logmeasures']['synflow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e20e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=[]\n",
    "y_data=[]\n",
    "for idx in range(len(runs)):\n",
    "    temp=runs[idx]['logmeasures']['synflow']\n",
    "    for i in range(len(temp)):\n",
    "        temp[i]=temp[i].item()\n",
    "    temp=torch.tensor(temp,dtype=torch.float32)\n",
    "    x_data.append(temp)\n",
    "    y_data.append(runs[idx]['testacc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c9863ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=torch.tensor([item.cpu().detach().numpy() for item in x_data],dtype=torch.float64).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8572aeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[0][1]==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8aa5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_data)):\n",
    "    indices = torch.sort(x_data[i],stable=True).indices\n",
    "    #对索引排序，获得原本元素的排名\n",
    "    indices=torch.sort(indices,stable=True).indices\n",
    "    for j in range(len(x_data[i])):\n",
    "        if x_data[i][j]==0:\n",
    "            continue\n",
    "        x_data[i][j]=indices[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce20ab26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([184.,   0.,   0.,   0., 158.,   0.,   0.,   0., 155.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0., 154.,   0.,   0.,   0., 163.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0., 161.,   0.,   0.,   0., 156.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0., 160.,   0.,   0.,   0., 159.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0., 157.,   0.,   0.,   0., 162.,   0.,   0.,   0.,\n",
       "          0., 185., 152., 153.,   0.,   0.,   0., 172.,   0.,   0.,   0., 165.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0., 171.,   0.,   0.,   0., 164.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0., 166.,   0.,   0.,   0., 173.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0., 170.,   0.,   0.,   0., 168.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0., 167.,   0.,   0.,   0., 169.,\n",
       "          0.,   0.,   0.,   0., 186., 150., 151.,   0.,   0.,   0., 182.,   0.,\n",
       "          0.,   0., 175.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 176.,   0.,\n",
       "          0.,   0., 180.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 181.,   0.,\n",
       "          0.,   0., 177.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 183.,   0.,\n",
       "          0.,   0., 174.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 178.,   0.,\n",
       "          0.,   0., 179.,   0.,   0.,   0.,   0., 187.], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4574526",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data=torch.tensor(y_data,dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6f0c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data=y_data/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4b01423",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx=[]\n",
    "trainy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dda0aadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(x_data)):\n",
    "    if isinf(torch.sum(x_data[i]).item()):\n",
    "        continue\n",
    "    trainx.append(x_data[i])\n",
    "    trainy.append(y_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "500b8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx=torch.tensor([item.cpu().detach().numpy() for item in trainx],dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38d8409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy=torch.tensor(trainy,dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aaf976ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15625 15625\n"
     ]
    }
   ],
   "source": [
    "print(len(trainx),len(trainy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "054c59ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx=trainx.cuda()\n",
    "trainy=trainy.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5d33e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这句话很关键，nn默认类型为float32\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "abd712ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class zyt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(zyt,self).__init__()\n",
    "        self.model1=Sequential(\n",
    "#             nn.BatchNorm1d(188),\n",
    "#            nn.LayerNorm(188),\n",
    "            Linear(188,128),\n",
    "#             nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            Linear(64,10),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            Linear(10,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.model1(x)\n",
    "        return x\n",
    "zyt1=zyt()\n",
    "zyt1=zyt1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7752336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#损失函数\n",
    "class SpearmanLossFunc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpearmanLossFunc,self).__init__()\n",
    "\n",
    "    def forward(self, t1,t2):\n",
    "        t1=t1.cpu().detach().numpy()\n",
    "        t2=t2.cpu().detach().numpy()\n",
    "        loss = -10*abs(stats.spearmanr(t1,t2,nan_policy='omit').correlation)\n",
    "        loss=torch.tensor(loss,requires_grad=True)\n",
    "        return loss\n",
    "    \n",
    "class MyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyLoss,self).__init__()\n",
    "\n",
    "    def forward(self, t1,t2):\n",
    "        t1=t1.cpu().detach().numpy()\n",
    "        t2=t2.cpu().detach().numpy()\n",
    "        loss=0\n",
    "        sample_size=500\n",
    "        sample=random.sample(range(len(trainx)),sample_size)\n",
    "        t1=t1.reshape(-1,)\n",
    "        for i in range(sample_size):\n",
    "            for j in range(sample_size):\n",
    "                if i==j:\n",
    "                    continue\n",
    "                loss+=log(1+exp(-np.sign((t1[sample[i]]-t1[sample[j]])*(t2[sample[i]]-t2[sample[j]]))))\n",
    "        loss=loss/(sample_size*(sample_size-1))\n",
    "        loss=torch.tensor(loss,requires_grad=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "88877252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn=torch.nn.MSELoss()\n",
    "loss_fn=SpearmanLossFunc()\n",
    "loss_fn=loss_fn.cuda()\n",
    "#优化器\n",
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(zyt1.parameters(),lr=learning_rate)\n",
    "#训练的轮数\n",
    "epoch=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1010c4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------第1轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第2轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第3轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第4轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第5轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第6轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第7轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第8轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第9轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第10轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第11轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第12轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第13轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第14轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第15轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第16轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第17轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第18轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第19轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第20轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第21轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第22轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第23轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第24轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第25轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第26轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第27轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第28轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第29轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第30轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第31轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第32轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第33轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第34轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第35轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第36轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第37轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第38轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第39轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第40轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第41轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第42轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第43轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第44轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第45轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第46轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第47轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第48轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第49轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n",
      "------第50轮训练开始-------\n",
      "tensor([[0.5110],\n",
      "        [0.7284],\n",
      "        [0.1835],\n",
      "        ...,\n",
      "        [0.2986],\n",
      "        [0.6453],\n",
      "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "loss:-1.2268932108497936\n"
     ]
    }
   ],
   "source": [
    "final_output=[]\n",
    "for i in range(epoch):\n",
    "    zyt1.train()\n",
    "    print(\"------第{}轮训练开始-------\".format(i+1))\n",
    "#     start_time=time.time()\n",
    "    total_train_loss=0\n",
    "    output=zyt1(trainx)\n",
    "    print(output)\n",
    "#     print(abs(stats.spearmanr(output.cpu().detach().numpy(),trainy.cpu().detach().numpy(),nan_policy='omit').correlation))\n",
    "    loss=loss_fn(output,trainy)\n",
    "    #优化\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()                \n",
    "    print(\"loss:{}\".format(loss.item()))\n",
    "#     end_time=time.time()\n",
    "#     print(\"time_cost:{}\".format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cedb37b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12268932108497937"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(stats.spearmanr(output.cpu().detach().numpy(),trainy.cpu().detach().numpy(),nan_policy='omit').correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa155c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5110],\n",
       "        [0.7284],\n",
       "        [0.1835],\n",
       "        ...,\n",
       "        [0.2986],\n",
       "        [0.6453],\n",
       "        [0.0451]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d5862d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8152, 0.9051, 0.8184,  ..., 0.8944, 0.6579, 0.8401], device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d86dfabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11317,\n",
       " 12368,\n",
       " 5271,\n",
       " 1256,\n",
       " 15302,\n",
       " 9442,\n",
       " 11171,\n",
       " 1173,\n",
       " 14640,\n",
       " 14189,\n",
       " 3138,\n",
       " 10664,\n",
       " 3379,\n",
       " 2404,\n",
       " 5072,\n",
       " 10564,\n",
       " 5248,\n",
       " 5505,\n",
       " 497,\n",
       " 12080,\n",
       " 15159,\n",
       " 9967,\n",
       " 14833,\n",
       " 13409,\n",
       " 12849,\n",
       " 15042,\n",
       " 14520,\n",
       " 6761,\n",
       " 13199,\n",
       " 1803,\n",
       " 7594,\n",
       " 5934,\n",
       " 12617,\n",
       " 5005,\n",
       " 10352,\n",
       " 9152,\n",
       " 2142,\n",
       " 7127,\n",
       " 11549,\n",
       " 12529,\n",
       " 12787,\n",
       " 11464,\n",
       " 7077,\n",
       " 11650,\n",
       " 11367,\n",
       " 11129,\n",
       " 2957,\n",
       " 3293,\n",
       " 14554,\n",
       " 4071,\n",
       " 6842,\n",
       " 14135,\n",
       " 4034,\n",
       " 9183,\n",
       " 1530,\n",
       " 3164,\n",
       " 1186,\n",
       " 10957,\n",
       " 2856,\n",
       " 1229,\n",
       " 10618,\n",
       " 3382,\n",
       " 4814,\n",
       " 5756,\n",
       " 14454,\n",
       " 11649,\n",
       " 4993,\n",
       " 3276,\n",
       " 8420,\n",
       " 3768,\n",
       " 6261,\n",
       " 7703,\n",
       " 12473,\n",
       " 8133,\n",
       " 7830,\n",
       " 14479,\n",
       " 13746,\n",
       " 14318,\n",
       " 7551,\n",
       " 1034,\n",
       " 10662,\n",
       " 8413,\n",
       " 13393,\n",
       " 2892,\n",
       " 12284,\n",
       " 12558,\n",
       " 12712,\n",
       " 10594,\n",
       " 10475,\n",
       " 2452,\n",
       " 7502,\n",
       " 9830,\n",
       " 14632,\n",
       " 8811,\n",
       " 630,\n",
       " 6149,\n",
       " 455,\n",
       " 977,\n",
       " 14731,\n",
       " 3076,\n",
       " 14686,\n",
       " 9214,\n",
       " 13869,\n",
       " 13168,\n",
       " 15086,\n",
       " 15207,\n",
       " 3855,\n",
       " 12261,\n",
       " 949,\n",
       " 4090,\n",
       " 9075,\n",
       " 12305,\n",
       " 2679,\n",
       " 5729,\n",
       " 8764,\n",
       " 4166,\n",
       " 4180,\n",
       " 3661,\n",
       " 1732,\n",
       " 14092,\n",
       " 13559,\n",
       " 11391,\n",
       " 2129,\n",
       " 7088,\n",
       " 12207,\n",
       " 1332,\n",
       " 9921,\n",
       " 3863,\n",
       " 15258,\n",
       " 11172,\n",
       " 946,\n",
       " 12443,\n",
       " 10623,\n",
       " 12527,\n",
       " 15171,\n",
       " 1500,\n",
       " 15164,\n",
       " 10980,\n",
       " 3241,\n",
       " 14575,\n",
       " 1573,\n",
       " 7715,\n",
       " 11287,\n",
       " 11631,\n",
       " 3162,\n",
       " 3760,\n",
       " 245,\n",
       " 2602,\n",
       " 6560,\n",
       " 12372,\n",
       " 14848,\n",
       " 13163,\n",
       " 4755,\n",
       " 12103,\n",
       " 5359,\n",
       " 15186,\n",
       " 6824,\n",
       " 10999,\n",
       " 3877,\n",
       " 6024,\n",
       " 7801,\n",
       " 696,\n",
       " 8395,\n",
       " 1319,\n",
       " 3429,\n",
       " 14954,\n",
       " 10271,\n",
       " 12181,\n",
       " 8230,\n",
       " 2078,\n",
       " 2000,\n",
       " 11937,\n",
       " 7574,\n",
       " 8994,\n",
       " 11500,\n",
       " 11320,\n",
       " 4625,\n",
       " 13569,\n",
       " 8986,\n",
       " 12583,\n",
       " 1664,\n",
       " 8802,\n",
       " 7684,\n",
       " 15255,\n",
       " 11606,\n",
       " 2128,\n",
       " 7969,\n",
       " 10439,\n",
       " 7625,\n",
       " 15237,\n",
       " 12394,\n",
       " 8514,\n",
       " 15363,\n",
       " 9606,\n",
       " 87,\n",
       " 8262,\n",
       " 13112,\n",
       " 7388,\n",
       " 5110,\n",
       " 8553,\n",
       " 11169,\n",
       " 1002,\n",
       " 3119,\n",
       " 14377,\n",
       " 3735,\n",
       " 9197,\n",
       " 10677,\n",
       " 3443,\n",
       " 3610,\n",
       " 7245,\n",
       " 2002,\n",
       " 627,\n",
       " 13422,\n",
       " 10097,\n",
       " 6309,\n",
       " 12736,\n",
       " 6902,\n",
       " 12184,\n",
       " 8650,\n",
       " 2287,\n",
       " 5163,\n",
       " 11112,\n",
       " 4239,\n",
       " 13653,\n",
       " 4761,\n",
       " 11188,\n",
       " 6233,\n",
       " 796,\n",
       " 722,\n",
       " 15122,\n",
       " 5201,\n",
       " 15299,\n",
       " 2804,\n",
       " 12400,\n",
       " 1751,\n",
       " 10651,\n",
       " 3836,\n",
       " 1584,\n",
       " 3905,\n",
       " 7494,\n",
       " 8174,\n",
       " 1760,\n",
       " 14813,\n",
       " 3220,\n",
       " 13584,\n",
       " 6117,\n",
       " 9977,\n",
       " 5334,\n",
       " 9983,\n",
       " 2584,\n",
       " 2685,\n",
       " 12148,\n",
       " 7063,\n",
       " 7615,\n",
       " 15257,\n",
       " 9063,\n",
       " 14623,\n",
       " 9364,\n",
       " 9176,\n",
       " 6123,\n",
       " 756,\n",
       " 12716,\n",
       " 3236,\n",
       " 12132,\n",
       " 9179,\n",
       " 7024,\n",
       " 14028,\n",
       " 7471,\n",
       " 13186,\n",
       " 10493,\n",
       " 881,\n",
       " 14806,\n",
       " 2428,\n",
       " 8517,\n",
       " 787,\n",
       " 7666,\n",
       " 4813,\n",
       " 10232,\n",
       " 7,\n",
       " 12562,\n",
       " 14212,\n",
       " 7124,\n",
       " 1857,\n",
       " 3950,\n",
       " 9577,\n",
       " 15265,\n",
       " 5218,\n",
       " 11005,\n",
       " 1844,\n",
       " 13320,\n",
       " 7135,\n",
       " 6479,\n",
       " 4095,\n",
       " 1240,\n",
       " 2495,\n",
       " 2280,\n",
       " 7951,\n",
       " 5900,\n",
       " 220,\n",
       " 1737,\n",
       " 14365,\n",
       " 9498,\n",
       " 4130,\n",
       " 3210,\n",
       " 4067,\n",
       " 316,\n",
       " 9157,\n",
       " 9721,\n",
       " 191,\n",
       " 2100,\n",
       " 8173,\n",
       " 5736,\n",
       " 4500,\n",
       " 13224,\n",
       " 8516,\n",
       " 2400,\n",
       " 4156,\n",
       " 2032,\n",
       " 11817,\n",
       " 10415,\n",
       " 7967,\n",
       " 9753,\n",
       " 7201,\n",
       " 4827,\n",
       " 10417,\n",
       " 13498,\n",
       " 6878,\n",
       " 7607,\n",
       " 1391,\n",
       " 10107,\n",
       " 7281,\n",
       " 12186,\n",
       " 11836,\n",
       " 12050,\n",
       " 541,\n",
       " 4665,\n",
       " 6930,\n",
       " 3159,\n",
       " 7711,\n",
       " 5613,\n",
       " 847,\n",
       " 15242,\n",
       " 4072,\n",
       " 5727,\n",
       " 10332,\n",
       " 12909,\n",
       " 11273,\n",
       " 10404,\n",
       " 15188,\n",
       " 15058,\n",
       " 7438,\n",
       " 13212,\n",
       " 384,\n",
       " 8870,\n",
       " 13206,\n",
       " 3440,\n",
       " 5621,\n",
       " 14699,\n",
       " 74,\n",
       " 2362,\n",
       " 10746,\n",
       " 2652,\n",
       " 3885,\n",
       " 5793,\n",
       " 2044,\n",
       " 14650,\n",
       " 2158,\n",
       " 14487,\n",
       " 3652,\n",
       " 2795,\n",
       " 10759,\n",
       " 10146,\n",
       " 4591,\n",
       " 6027,\n",
       " 4741,\n",
       " 12962,\n",
       " 9931,\n",
       " 9462,\n",
       " 1454,\n",
       " 2126,\n",
       " 2504,\n",
       " 15031,\n",
       " 7734,\n",
       " 1179,\n",
       " 14967,\n",
       " 7420,\n",
       " 7798,\n",
       " 2657,\n",
       " 14159,\n",
       " 11768,\n",
       " 7171,\n",
       " 7671,\n",
       " 13632,\n",
       " 13002,\n",
       " 6551,\n",
       " 1513,\n",
       " 12898,\n",
       " 1596,\n",
       " 6458,\n",
       " 11488,\n",
       " 652,\n",
       " 14221,\n",
       " 1461,\n",
       " 6960,\n",
       " 5763,\n",
       " 7531,\n",
       " 1936,\n",
       " 11067,\n",
       " 6070,\n",
       " 14711,\n",
       " 3643,\n",
       " 4041,\n",
       " 9648,\n",
       " 4713,\n",
       " 10268,\n",
       " 10437,\n",
       " 3754,\n",
       " 11891,\n",
       " 14455,\n",
       " 13732,\n",
       " 10551,\n",
       " 251,\n",
       " 3654,\n",
       " 7608,\n",
       " 1903,\n",
       " 11968,\n",
       " 6293,\n",
       " 5071,\n",
       " 1609,\n",
       " 9322,\n",
       " 12457,\n",
       " 13716,\n",
       " 8317,\n",
       " 2942,\n",
       " 9503,\n",
       " 3497,\n",
       " 3437,\n",
       " 6903,\n",
       " 14276,\n",
       " 10390,\n",
       " 13080,\n",
       " 10269,\n",
       " 7925,\n",
       " 4848,\n",
       " 4503,\n",
       " 12,\n",
       " 35,\n",
       " 14280,\n",
       " 10330,\n",
       " 3300,\n",
       " 10733,\n",
       " 2996,\n",
       " 14492,\n",
       " 6792,\n",
       " 14173,\n",
       " 11263,\n",
       " 383,\n",
       " 1557,\n",
       " 9472,\n",
       " 4211,\n",
       " 7745,\n",
       " 11825,\n",
       " 12817,\n",
       " 11392,\n",
       " 8049,\n",
       " 10,\n",
       " 370,\n",
       " 9850,\n",
       " 10875,\n",
       " 7854,\n",
       " 5594,\n",
       " 8369,\n",
       " 8518,\n",
       " 5143,\n",
       " 11331,\n",
       " 14784,\n",
       " 14953,\n",
       " 6011,\n",
       " 6532,\n",
       " 10503,\n",
       " 3031,\n",
       " 224,\n",
       " 13617,\n",
       " 7242,\n",
       " 2964,\n",
       " 7166,\n",
       " 10944,\n",
       " 4014,\n",
       " 14964,\n",
       " 1813,\n",
       " 12584,\n",
       " 9414,\n",
       " 11029,\n",
       " 3467,\n",
       " 8289,\n",
       " 9474,\n",
       " 247,\n",
       " 8872,\n",
       " 7821,\n",
       " 4885]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61f499c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
